{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+TFLHCvs+gZXpWnkuxjk6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodyRuan/Kaggle_Popcorn/blob/main/Bag_of_Words_Meets_Bags_of_Popcorn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfF0tA-SeJTH",
        "outputId": "3ebc3395-e550-4f79-d4b4-69f7a73393cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n",
        "!pip install nltk\n",
        "!pip install scikit-learn\n",
        "!pip install pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi0cGaygwkeC",
        "outputId": "7bf085b6-6a4a-4bfb-dc38-e8339ca35346"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar os dados\n",
        "labeled_train_data = pd.read_csv('labeledTrainData.tsv', delimiter='\\t')\n",
        "test_data = pd.read_csv('testData.tsv', delimiter='\\t')\n"
      ],
      "metadata": {
        "id": "EbPXbpVwwpzh"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para limpar e preprocessar os textos\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'<br />', ' ', text)\n",
        "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_words = [word for word in tokens if word not in stop_words]\n",
        "    return filtered_words\n",
        "\n",
        "# Aplicar preprocessamento nos textos\n",
        "labeled_train_data['clean_review'] = labeled_train_data['review'].apply(preprocess_text)\n",
        "test_data['clean_review'] = test_data['review'].apply(preprocess_text)\n"
      ],
      "metadata": {
        "id": "Yl_3scgFwsYB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo Word2Vec\n",
        "model = Word2Vec(sentences=labeled_train_data['clean_review'], vector_size=100, window=5, min_count=2, workers=4)\n",
        "model.train(labeled_train_data['clean_review'], total_examples=len(labeled_train_data['clean_review']), epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8qBwJLGwwgp",
        "outputId": "244b6a92-f408-45c9-9537-5aecd72cfc80"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28452612, 29878200)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def review_to_vector(review, model, num_features):\n",
        "    feature_vec = np.zeros((num_features,), dtype=\"float32\")\n",
        "    num_words = 0\n",
        "    for word in review:\n",
        "        if word in model.wv:\n",
        "            num_words += 1\n",
        "            feature_vec = np.add(feature_vec, model.wv[word])\n",
        "    if num_words > 0:\n",
        "        feature_vec = np.divide(feature_vec, num_words)\n",
        "    return feature_vec\n",
        "\n",
        "num_features = 100\n",
        "train_data_vecs = np.array([review_to_vector(review, model, num_features) for review in labeled_train_data['clean_review']])\n",
        "test_data_vecs = np.array([review_to_vector(review, model, num_features) for review in test_data['clean_review']])\n"
      ],
      "metadata": {
        "id": "w-zxxbdGwyND"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir os dados de treino em treino e validação\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(train_data_vecs, labeled_train_data['sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Treinar o classificador RandomForest\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Previsão e avaliação\n",
        "y_pred = clf.predict(X_valid)\n",
        "roc_score = roc_auc_score(y_valid, y_pred)\n",
        "print(f'ROC AUC Score: {roc_score}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piCKvrMUwz1G",
        "outputId": "9fb06ad9-b03d-488b-8b46-b9ea25ecd71d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC Score: 0.8332186067067234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Previsões no conjunto de teste\n",
        "test_predictions = clf.predict(test_data_vecs)\n",
        "\n",
        "# Criação do arquivo de submissão\n",
        "submission = pd.DataFrame({'id': test_data['id'], 'sentiment': test_predictions})\n",
        "submission.to_csv('submission.csv', index=False)\n"
      ],
      "metadata": {
        "id": "T-u1Y0Qkw1ay"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}